# -*- coding: utf-8 -*-
"""Uber cab Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_vlDVkjTwrzZ1wcHr1XPZ4vNTZBUC03U
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import os
import warnings

!wget https://www.dropbox.com/s/ncqb2ctkg7dallk/weather.csv

!wget :https://www.dropbox.com/s/brixkogrmhan6ed/cab_rides.csv

def reduce_mem_usage(df):
    """ iterate through all the columns of a dataframe and modify the data type
        to reduce memory usage.
    """
    start_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))

    for col in df.columns:
        col_type = df[col].dtype

        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
        else:
            df[col] = df[col].astype('category')

    end_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))
    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))

    return df


def import_data(file):
    """create a dataframe and optimize its memory usage"""
    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)
    df = reduce_mem_usage(df)
    return df

cab_data=pd.read_csv('cab_rides.csv')
cab_data=reduce_mem_usage(cab_data)
weather_data=pd.read_csv('Weather Data.csv')
weather_data=reduce_mem_usage(weather_data)

cab_data.head()

import datetime
cab_data['date'] = pd.to_datetime(cab_data['time_stamp']).dt.date
weather_data['Date/Time'] = pd.to_datetime(weather_data['Date/Time']).dt.date

weather_data.head()

cab_data.shape

weather_data.shape

cab_data.describe()

weather_data.describe()

weather_data.info()

cab_data.info()

a=pd.concat([cab_data,weather_data])

a.head()

# Convert the 'date' column to datetime objects
a['date'] = pd.to_datetime(a['date'])

# Now you can extract day and hour
a['day'] = a.date.dt.day
a['hour'] = a.date.dt.hour

a.tail()

# Add a new category '0' to categorical columns before filling NaNs
for col in a.select_dtypes(include=['category']):
    a[col] = a[col].cat.add_categories([0]).fillna(0)

# Now fill NaNs in all other columns with 0
a.fillna(0, inplace=True)

a.groupby('cab_type').count()

a.groupby('cab_type').count().plot.bar()

a['price'].value_counts().plot(kind = 'bar',figsize=(100,50),color='red')

a['hour'].value_counts().plot(kind = 'bar',figsize=(10,5),color='blue')

plt.plot(a['hour'],a['price'])
plt.xlabel('hour')
plt.ylabel('price')
plt.title('hour vs price')
plt.show()

plt.plot(a['Temp_C'],a['price'])
plt.xlabel('Temp')
plt.ylabel('price')
plt.title('Temp vs price')
plt.show()

a.columns

x1=a[['distance','price','hour','Temp_C','day','Wind Speed_km/h','surge_multiplier','Press_kPa',"Rel Hum_%"]]
y1=a['price']

x_train,x_test,y_train,y_test=train_test_split(x1,y1,test_size=0.2,random_state=42)

L=LinearRegression()

L.fit(x_train,y_train)

prediction = L.predict(x_test)  # Use x_test for predictions

df=pd.DataFrame({'Actual': y_test, 'Predicted': prediction})

df

