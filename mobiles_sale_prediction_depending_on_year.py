# -*- coding: utf-8 -*-
"""Mobiles sale prediction depending on year

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dxBncuCRTM2xgBxNP-6LdX1GyKISYGb1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv('Mobiles.csv')

data.head()

data

data.describe()

data.info()

data.shape

data.tail()

data.columns

import pandas as pd
import seaborn as sns

# Assuming 'data' is your DataFrame in wide format
data_long = pd.melt(data, id_vars=['Units Sold (million )'], var_name='Brand', value_name='Value')

# Now you can create the histplot with hue
sns.histplot(data_long, x='Units Sold (million )', hue='Brand')

plt.hist(data['Units Sold (million )'],edgecolor='black',color='red')

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

x=data.drop('Units Sold (million )',axis=1)
y=data['Units Sold (million )']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
L=LinearRegression()

import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

# Identify categorical columns
categorical_cols = x_train.select_dtypes(include=['object']).columns

# Create a ColumnTransformer to handle categorical features
# Handle unknown categories by ignoring them
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ],
    remainder='passthrough'  # Keep numerical columns as they are
)

# Apply the preprocessing to your training and test data
x_train_encoded = preprocessor.fit_transform(x_train)
x_test_encoded = preprocessor.transform(x_test)

# Now, try fitting the model again
L.fit(x_train_encoded, y_train)

y_pred=L.predict(x_test_encoded)

print(mean_squared_error(y_test,y_pred))
print(round(100*L.score(x_test_encoded,y_test),2),'%')